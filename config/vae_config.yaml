dataset_params:
  img_path: 'data/poleno'
  img_channels : 1
  img_size : 200
  img_interpolation : 256
  name: 'Holography'

ddpm_params:
  down_channels: [ 256, 384, 512, 768 ]
  mid_channels: [ 768, 512, 768 ]
  down_sample: [ True, True, True ]
  attn_down : [True, True, True]
  time_emb_dim: 512
  norm_channels: 32
  num_heads: 16
  conv_out_channels : 256
  num_down_layers : 2
  num_mid_layers : 2
  num_up_layers : 2

autoencoder_params:
  z_channels : 3
  codebook_size : 8192
  down_channels : [64, 128, 256, 256]
  mid_channels : [256, 256]
  down_sample : [True, True, True]
  attns : [False, False, False]
  norm_channels: 32
  num_heads: 4
  num_down_layers : 2
  num_mid_layers : 2
  num_up_layers : 2

train_params:
  seed : 42
  task_name : 'holographic_pollen'
  ldm_lr :  0.000005
  ldm_epochs : 20
  ldm_batch_size : 16
  ldm_num_timesteps : 1000
  ldm_beta_start : 0.0015
  ldm_beta_end : 0.0195
  ldm_ckpt_steps : 1500
  autoencoder_lr : 0.00005
  autoencoder_epochs : 20
  autoencoder_batch_size : 8
  autoencoder_steps_per_optimization : 4
  autoencoder_img_save_steps : 1500
  autoencoder_ckpt_steps : 1500
  codebook_weight : 1
  commitment_beta : 0.25 # https://arxiv.org/pdf/1711.00937.pdf
  perceptual_weight: 1 
  discriminator_start_step : 1500 # Set t step when VAE no longer improves with mse and lpips
  discriminator_loss : MSELoss
  discriminator_weight : 0.5
  vqvae_autoencoder_ckpt_name : 'vqvae_autoencoder_ckpt'
  vqvae_discriminator_ckpt_name : 'vqvae_discriminator_ckpt'
  vqvae_latents_representations : 'vqvae_latents_representations'

vqvae_inference_params :
  save_images : True
  num_samples : 8
  num_grid_rows : 8
  upscale_latent_dim : True
  model_ckpt : 'latest.pth'
  