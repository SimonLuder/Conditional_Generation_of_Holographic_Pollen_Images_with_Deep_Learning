{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explorative Data Analysis Poleno Dataset\n",
    "\n",
    "This notebook was used to perform the Explorative Data Analysis on the Poleno dataset. It also contains code for the pre-processing and is used to create the train, validation and test split of the cleaned dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "workdir = \"Generative Diffusion Models for 3D Geometric Objects\"\n",
    "if workdir in os.getcwd() and os.path.basename(os.getcwd()) != workdir:\n",
    "    os.chdir(\"..\")\n",
    "\n",
    "from utils import data_processing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original Dataset\n",
    "Download the tables from `poleno_marvel.db` and save the tables as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = \"Z:/marvel/marvel-fhnw/data/Poleno/poleno_marvel.db\"\n",
    "csv_dir = \"data/poleno/poleno_marvel/\"\n",
    "download_db = False\n",
    "\n",
    "if download_db:\n",
    "\n",
    "    # create csv folder if it doesn't exist\n",
    "    Path(csv_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Connect to the SQLite database\n",
    "    conn = sqlite3.connect(db_path)\n",
    "\n",
    "    # get names of all tables\n",
    "    all_tables = pd.read_sql_query(\"SELECT name FROM sqlite_master WHERE type='table';\", conn) # read data from database, table poleno\n",
    "\n",
    "    # download tables\n",
    "    for _, table in all_tables.iterrows():\n",
    "        if not os.path.isfile(os.path.join(csv_dir, f\"{table['name']}.csv\")):\n",
    "            print(f\"Downloading table: {table['name']}\")\n",
    "            df = pd.read_sql_query(f\"SELECT * FROM {table['name']}\", conn)\n",
    "            df.to_csv(os.path.join(csv_dir, f\"{table['name']}.csv\"), index=False)\n",
    "            pass\n",
    "\n",
    "    # close the database connection\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load csv tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels                      = pd.read_csv(os.path.join(csv_dir, \"labels.csv\"))\n",
    "computed_data_full          = pd.read_csv(os.path.join(csv_dir, \"computed_data_full.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computed_data_full.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table `computed_data_full` contains a total of 968234 samples. However, there are many samples with nan values in columns that describe measured values like `bbox_area`, `convex_area` or `orientation`. \n",
    "\n",
    "Next are the columns that contain numerical measurements which are extractet from the shape of the corresponding sample. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_tags = ['event_id', 'dataset_id', 'label', 'rec_path', 'image_nr']\n",
    "measurements_cols = [x for x in computed_data_full if x not in sample_tags]\n",
    "measurements_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Nr of unique Labels\", len(computed_data_full[\"label\"].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genus = computed_data_full[\"label\"].apply(lambda x: x.split(\" \")[0])\n",
    "print(\"Nr of different genuses:\", len(set(genus)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recalculation of numerical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These measurements are extracted using `skimage.measure.regionprops()`. In order to have the maximum amount of data available for the training and to have a consistent basis for calculating these measured features, they will be recalculated from the raw images over the complete dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load `computed_data_full_re` which contains the recaltulated features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computed_data_full_re = pd.read_csv(os.path.join(csv_dir, \"computed_data_full_re.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computed_data_full_re.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_per_event_id = computed_data_full_re[\"event_id\"].value_counts()\n",
    "valid_samples_per_event_id = samples_per_event_id[samples_per_event_id == 2].index\n",
    "samples_per_event_id.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop columns with more then two samples per `event_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computed_data_full_re = computed_data_full_re.loc[computed_data_full_re[\"event_id\"].isin(valid_samples_per_event_id)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainig Dataset\n",
    "\n",
    "Create the dataset used for training, validation and testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum number of labels per dataset_id\n",
    "\n",
    "The `label` consists of the combination of `genus` and `species/type`. As shown bellow, the dataset has only one `label` class per `dataset_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_per_dataset_id = computed_data_full_re.groupby([\"dataset_id\", \"label\"]).count().reset_index().rename(columns={\"label\": \"num_distinct_labels\"}).  \\\n",
    "    groupby(\"dataset_id\").count().reset_index()[[\"dataset_id\", \"num_distinct_labels\"]].sort_values(\"num_distinct_labels\", ascending=False)\n",
    "print(labels_per_dataset_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum number of dataset_ids with specific labels\n",
    "\n",
    "However, a `label` might appear in multiple `dataset_id` folders. This should be taken into account when creating a train, val, test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ids_per_label = computed_data_full.groupby([\"label\", \"dataset_id\"]).count().reset_index().rename(columns={\"dataset_id\": \"num_dataset_folders\"}). \\\n",
    "    groupby(\"label\").count().reset_index()[[\"label\", \"num_dataset_folders\"]].sort_values(\"num_dataset_folders\", ascending=False)\n",
    "print(dataset_ids_per_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop columns with any missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computed_data_full_filtered = computed_data_full_re.dropna()\n",
    "print(f\"Samples in original dataset: {len(computed_data_full)}\\nAfter dropping samples with nan : {len(computed_data_full_filtered)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove labels with small sample count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples_per_label = 2000\n",
    "\n",
    "samples_per_label = computed_data_full_filtered.value_counts(\"label\").reset_index()\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.bar(x=samples_per_label[\"label\"], height=samples_per_label[\"count\"])\n",
    "plt.axhline(min_samples_per_label, color='red', ls='dotted')\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Label distribution in the dataset\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The visualization above shows the number of samples per label class. A class is made up of the genus and the species. There are several species per genus. Since some species are indicated with placeholders, e.g. `sp. 0` or `sp. 1`, it is not possible to know exactly how they relate to each other.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a next step the labels with a sample count below `min_samples_per_label` are dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_labels = list(samples_per_label.loc[samples_per_label[\"count\"] >= min_samples_per_label][\"label\"])\n",
    "computed_data_full_filtered = computed_data_full_filtered.loc[computed_data_full_filtered[\"label\"].isin(valid_labels)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next the feature columns are normalized per column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df):\n",
    "    return (df-df.mean())/df.std()\n",
    "\n",
    "computed_data_full_filtered[measurements_cols] = normalize(computed_data_full_filtered[measurements_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore a `filenames` column is created for easyer sampling during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computed_data_full_filtered[\"filenames\"] = computed_data_full_filtered[\"dataset_id\"] + \"/\" + computed_data_full_filtered[\"rec_path\"] \n",
    "computed_data_full_filtered[\"filenames\"].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the same reason a `class_id` column is created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_id = {c:i for i, c in enumerate(set(list(computed_data_full_filtered[\"dataset_id\"])))}\n",
    "computed_data_full_filtered[\"class_id\"] = computed_data_full_filtered[\"dataset_id\"].apply(lambda x: class_to_id[x])\n",
    "\n",
    "label_to_id = {c:i for i, c in enumerate(set(list(computed_data_full_filtered[\"label\"])))}\n",
    "computed_data_full_filtered[\"label_id\"] = computed_data_full_filtered[\"label\"].apply(lambda x: label_to_id[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To review the zero shot capabilities of the model, it is necessary that the test data set contains new species unknown to the model. Due to the uncertainties mentioned above, the **unknown classes are selected based on genus**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genus = computed_data_full_filtered[\"label\"].apply(lambda x: x.split(\" \")[0])\n",
    "print(\"Nr of different genuses:\", len(set(genus)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Nr of unique Labels\", len(computed_data_full_filtered[\"label\"].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples_per_label.loc[:, \"genus\"] = samples_per_label[\"label\"].apply(lambda x: x.split(\" \")[0])\n",
    "# # samples_per_label = samples_per_label.sort_values(\"genus\")\n",
    "\n",
    "# plt.figure(figsize=(14, 5))\n",
    "# plt.bar(x=samples_per_label[\"genus\"], height=samples_per_label[\"count\"])\n",
    "# plt.axhline(min_samples_per_label, color='red', ls='dotted')\n",
    "# plt.xticks(rotation=90)\n",
    "# plt.title(\"Label distribution in the dataset\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples_per_genus = samples_per_label[[\"genus\", \"count\"]].groupby(\"genus\").sum().sort_values(by=\"count\").reset_index()\n",
    "# # samples_per_genus\n",
    "# list(samples_per_genus.head(5)[\"genus\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels from the genuses `Lolium`, `Phytophthora`, `Arrhenatherum`, `Holcus` and `Cynosurus` are selected to only appear in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_only = ['Lolium', 'Phytophthora', 'Arrhenatherum', 'Holcus', 'Cynosurus']\n",
    "\n",
    "# # select columns with test only genuses\n",
    "# eval_only = \"|\".join(test_genus for test_genus in eval_only)\n",
    "# df_eval_only = computed_data_full_filtered.loc[computed_data_full_filtered[\"label\"].str.contains(eval_only)]\n",
    "\n",
    "# # remove them from computed_data_full_filtered\n",
    "# computed_data_full_filtered = computed_data_full_filtered.drop(index=df_eval_only.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is subsequently split into a train validation test dataset. The spliting balances the amount of labels in the validation and the test set. For the test set, an amount of 25 events (50 samples) per label is selected. For the validation set, an amount of 10 (20 samples) events is selected per dataset. The other samples are present in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_events(df, n, random_state=42):\n",
    "\n",
    "    \"\"\"\n",
    "    This function samples events from a dataframe based on their labels.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The input dataframe. It should contain columns 'event_id' and 'label'.\n",
    "    n (int): The number of events to sample from each label.\n",
    "    random_state (int, optional): The seed for the random number generator. Default is 42.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: A dataframe containing the sampled events.\n",
    "\n",
    "    The function first identifies unique events in the input dataframe. It then samples 'n' events from each label \n",
    "    using the 'sample' method of pandas.DataFrame.groupby. The sampled events are returned as a dataframe.\n",
    "    \"\"\"\n",
    "\n",
    "    events_in_classes = df[[\"event_id\", \"label\"]].drop_duplicates()\n",
    "    sampled_events = events_in_classes.groupby(\"label\").sample(n, random_state=random_state)\n",
    "    sampled_event_ids = list(sampled_events[\"event_id\"])\n",
    "\n",
    "    return df[df[\"event_id\"].isin(sampled_event_ids)]\n",
    "\n",
    "    \n",
    "\n",
    "test = sample_events(computed_data_full_re, n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "n_samples_test = 25\n",
    "n_samples_val = 25\n",
    "recreate_datasets = True\n",
    "\n",
    "if recreate_datasets:\n",
    "\n",
    "    dataset_dir =  \".\"\n",
    "    # dataset_dir = \"Z:\\simon_luder\\Generative_Diffusion_Models_for_3D_Geometric_Objects\"\n",
    "\n",
    "    Path(dataset_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "    # computed_data_full_filtered = computed_data_full_filtered.loc[computed_data_full_filtered[\"dataset_id\"].isin([\"11ee037f-6ea4-cbb8-a9fd-66f2ec8a65cb\"])]\n",
    "\n",
    "    # set df_train as the complete computed_data_full_filtered\n",
    "    df_train = computed_data_full_filtered\n",
    "\n",
    "    # sample \n",
    "    # df_test = df_train.groupby(\"label\").sample(n_samples_test, random_state=random_state)\n",
    "    df_test = sample_events(df_train, n=n_samples_test, random_state=random_state)\n",
    "    # remove samples from df_test in df_train\n",
    "    df_train = df_train.drop(index=df_test.index)\n",
    "\n",
    "    # # append evaluation only genuses\n",
    "    # # df_test_eval_only = df_eval_only.groupby(\"label\").sample(n_samples_test, random_state=random_state)\n",
    "    # df_test_eval_only = sample_events(df_eval_only, n=n_samples_test, random_state=random_state)\n",
    "    # df_test = pd.concat([df_test, df_test_eval_only])\n",
    "\n",
    "    # df_val = df_train.groupby(\"label\").sample(n_samples_val, random_state=random_state)\n",
    "    df_val = sample_events(df_train, n=n_samples_val, random_state=random_state)\n",
    "    # remove samples from df_val in df_train\n",
    "    df_train = df_train.drop(df_val.index)\n",
    "\n",
    "    df_train.to_csv(os.path.join(dataset_dir, \"labels_train.csv\"), index=False)\n",
    "    df_val.to_csv(os.path.join(dataset_dir, \"labels_val.csv\"), index=False)\n",
    "    df_test.to_csv(os.path.join(dataset_dir, \"labels_test.csv\"), index=False)\n",
    "\n",
    "    print(f\"Generated Datasets \\nTrain: {len(df_train)} \\nVal: {len(df_val)} ({n_samples_val} per class) \\nTest: {len(df_test)} ({n_samples_test} per class)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sandbox\n",
    "\n",
    "The code which follofs from here on has been used only for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_old = pd.read_csv(\"Z:\\simon_luder\\Generative_Diffusion_Models_for_3D_Geometric_Objects/labels_train.csv\")\n",
    "val_old = pd.read_csv(\"Z:\\simon_luder\\Generative_Diffusion_Models_for_3D_Geometric_Objects/labels_val.csv\")\n",
    "test_old = pd.read_csv(\"Z:\\simon_luder\\Generative_Diffusion_Models_for_3D_Geometric_Objects/labels_test.csv\")\n",
    "\n",
    "label_to_id = {c:i for i, c in enumerate(set(list(train_old[\"label\"])))}\n",
    "\n",
    "train_old[\"label_id\"] = train_old[\"label\"].apply(lambda x: label_to_id[x])\n",
    "val_old[\"label_id\"] = val_old[\"label\"].apply(lambda x: label_to_id[x])\n",
    "test_old[\"label_id\"] = test_old[\"label\"].apply(lambda x: label_to_id[x])\n",
    "\n",
    "train_old.to_csv(\"labels_train.csv\", index=False, encoding=\"utf-8\")\n",
    "val_old.to_csv(\"labels_val.csv\", index=False, encoding=\"utf-8\")\n",
    "test_old.to_csv(\"labels_test.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# update with genus id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_old = pd.read_csv(\"Z:\\simon_luder\\Generative_Diffusion_Models_for_3D_Geometric_Objects/labels_train.csv\")\n",
    "val_old = pd.read_csv(\"Z:\\simon_luder\\Generative_Diffusion_Models_for_3D_Geometric_Objects/labels_val.csv\")\n",
    "test_old = pd.read_csv(\"Z:\\simon_luder\\Generative_Diffusion_Models_for_3D_Geometric_Objects/labels_test.csv\")\n",
    "\n",
    "genus_to_id = {c:i for i, c in enumerate(set([x[0] for x in train_old[\"label\"].str.split()]))}\n",
    "\n",
    "train_old[\"genus_id\"] = train_old[\"label\"].apply(lambda x:genus_to_id[x.split()[0]])\n",
    "val_old[\"genus_id\"] = val_old[\"label\"].apply(lambda x:genus_to_id[x.split()[0]])\n",
    "test_old[\"genus_id\"] = test_old[\"label\"].apply(lambda x:genus_to_id[x.split()[0]])\n",
    "\n",
    "train_old.to_csv(\"labels_train.csv\", index=False, encoding=\"utf-8\")\n",
    "val_old.to_csv(\"labels_val.csv\", index=False, encoding=\"utf-8\")\n",
    "test_old.to_csv(\"labels_test.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    \"ldm_cls_8_512_e5\",\n",
    "    # \"ldm_clstbl_8_512_e5x\",\n",
    "    \"ldm_clstbl_8_512_e5\",\n",
    "    \"ldm_tbl_8_512_e5x\",\n",
    "    # \"ldm_tbl_8_512_e5\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in model_names:\n",
    "    testset = pd.read_csv(\"Z:\\simon_luder\\Generative_Diffusion_Models_for_3D_Geometric_Objects/labels_test.csv\")\n",
    "    testset[\"filenames\"] = testset[\"filenames\"].apply(lambda x: os.path.join(f\"holographic_pollen/{model_name}/test/images/\", x.split(\"/\")[-1]))\n",
    "    testset.to_csv(f\"labels_test_{model_name}.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_id = {c:i for i, c in enumerate(set(list(train_old[\"label\"])))}\n",
    "train_old[\"label_id\"] = train_old[\"label\"].apply(lambda x: label_to_id[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_old = pd.read_csv(\"Z:\\simon_luder\\Generative_Diffusion_Models_for_3D_Geometric_Objects/labels_train.csv\")\n",
    "train_new = pd.read_csv(\"labels_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_new = pd.read_csv(\"labels_train.csv\")\n",
    "test = train_new.groupby(\"genus_id\").sample(1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv(\"labels_train_mini.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train[\"label\"].value_counts().to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of a debug dataset that only contains one sample per `class_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "dataset_dir = \"Z:\\simon_luder\\Generative_Diffusion_Models_for_3D_Geometric_Objects\"\n",
    "create_debug_set = False\n",
    "\n",
    "if create_debug_set:\n",
    "\n",
    "    df = pd.read_csv(os.path.join(dataset_dir, \"labels_test.csv\"))\n",
    "    df = df.groupby(\"class_id\").sample(1, random_state=random_state)\n",
    "    df.to_csv(os.path.join(dataset_dir, \"labels_test_mini.csv\", index = False))\n",
    "\n",
    "    df = pd.read_csv(os.path.join(dataset_dir, \"labels_val.csv\"))\n",
    "    df = df.groupby(\"class_id\").sample(1, random_state=random_state)\n",
    "    df.to_csv(os.path.join(dataset_dir, \"labels_val_mini.csv\", index = False))\n",
    "\n",
    "    df = pd.read_csv(os.path.join(dataset_dir, \"labels_train.csv\"))\n",
    "    df = df.groupby(\"class_id\").sample(1, random_state=random_state)\n",
    "    df.to_csv(os.path.join(dataset_dir, \"labels_train_mini.csv\", index = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1=pd.read_csv(\"Z:\\simon_luder\\Generative_Diffusion_Models_for_3D_Geometric_Objects/labels_val.csv\")\n",
    "df2=pd.read_csv(\"Z:\\simon_luder\\Generative_Diffusion_Models_for_3D_Geometric_Objects/labels_train.csv\")\n",
    "\n",
    "# Assuming df1 and df2 are your DataFrames\n",
    "overlap = pd.merge(df1, df2, how='inner')\n",
    "\n",
    "# Check if the overlap DataFrame is empty\n",
    "if not overlap.empty:\n",
    "    print(\"There are overlapping rows.\")\n",
    "else:\n",
    "    print(\"No overlapping rows.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "three_D",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
