{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import os\n",
    "import git\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import math\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def get_git_root(path):\n",
    "        git_repo = git.Repo(path, search_parent_directories=True)\n",
    "        git_root = git_repo.git.rev_parse(\"--show-toplevel\")\n",
    "        return git_root\n",
    "\n",
    "os.chdir(get_git_root(\".\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration of runs\n",
    "\n",
    "ENTITY=\"simonluder\"\n",
    "PROJECT=\"MSE_P7\"\n",
    "ARTIFACT = \"validation_results\"\n",
    "\n",
    "RUNS = [\n",
    "    \"2D_GeoShape_32_linear_tabular_1704819570\",\n",
    "    \"2D_GeoShape_32_linear_cnn_image_1704819570\",\n",
    "    \"2D_GeoShape_32_linear_clip_text_1704819570\",\n",
    "    \"2D_GeoShape_32_linear_clip_image_1704819570\",\n",
    "    \"2D_GeoShape_64_linear_tabular_1705056127\",\n",
    "    \"2D_GeoShape_64_linear_cnn_image_1705051540\",\n",
    "    \"2D_GeoShape_64_linear_clip_text_1705056262\",\n",
    "    \"2D_GeoShape_64_linear_clip_image_1705056262\", \n",
    "    \"2D_GeoShape_sub100_32_linear_tabular_1705411529\", \n",
    "    \"2D_GeoShape_sub100_32_linear_cnn_image_1705405821\", \n",
    "    \"2D_GeoShape_sub100_32_linear_clip_text_1705410786\",\n",
    "    \"2D_GeoShape_sub100_32_linear_clip_image_1705569629\"\n",
    "    \n",
    "    ]\n",
    "\n",
    "LOG_DIR = \"runs/\"\n",
    "\n",
    "download = True\n",
    "\n",
    "color_palette = {\"clip_text\": \"#7852A9\", \"clip_image\":\"#80de81\", \"tabular\": \"#4285c6\", \"cnn_image\":\"#8FD4CB\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "\n",
    "def get_config(filepath):\n",
    "\n",
    "    with open(filepath, 'r') as f:\n",
    "        return json.load(f)\n",
    "       \n",
    "\n",
    "def get_metrics(filepath):\n",
    "\n",
    "    with open(filepath, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    data_train = []\n",
    "    data_val = []\n",
    "    data_test = []\n",
    "\n",
    "    for entry in data:\n",
    "\n",
    "        entry_train = entry.get(\"train\")\n",
    "        entry_val = entry.get(\"val\")\n",
    "        entry_test = entry.get(\"test\")\n",
    "\n",
    "        if entry_train:\n",
    "            data_train.append(entry_train)\n",
    "\n",
    "        if entry_val:\n",
    "            data_val.append(entry_val)\n",
    "\n",
    "        if entry_test:\n",
    "            data_test.append(entry_test)\n",
    "\n",
    "    return data_train, data_val, data_test\n",
    "\n",
    "def postprocess_df_val(df_val):\n",
    "    df = df_val.explode('samples')\n",
    "    df = df.reset_index(drop=True)\n",
    "    df_samples = pd.json_normalize(df[\"samples\"])\n",
    "    df = pd.concat([df.drop(columns=['samples']), df_samples], axis=1)\n",
    "\n",
    "    df[\"path_original\"] = df[\"path_original\"].str.replace(\"/workspace\", \".\")\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def postprocess(df):\n",
    "    \n",
    "    pattern = r'(clip_text|clip_image|tabular|cnn_image)'\n",
    "    df['encoder'] = df['run'].str.extract(pattern, expand=False)\n",
    "\n",
    "    pattern = r'(_32_|_64_)'\n",
    "    df['image_size'] = df['run'].str.extract(pattern, expand=False).str.replace(\"_\", \"\").astype(int)\n",
    "\n",
    "    pattern = r'(sub100)'\n",
    "    df['subset'] = df['run'].str.extract(pattern, expand=False).str.replace(\"sub\", \"\")\n",
    "    df.loc[df['subset'].isna(), \"subset\"] = \"1000\"\n",
    "    df['subset'] = df['subset'].astype(int)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training datasets\n",
    "\n",
    "ds_path = \"./data\"\n",
    "\n",
    "# load dataset\n",
    "datasets = list()\n",
    "for dataset in os.listdir(ds_path):\n",
    "    dataset_path = os.path.join(ds_path, dataset, \"labels.csv\")\n",
    "    datasets.append(pd.read_csv(dataset_path))\n",
    "df_datasets = pd.concat(datasets)\n",
    "\n",
    "\n",
    "# load config\n",
    "configs = list()\n",
    "for run in RUNS:\n",
    "    config = get_config(filepath = f\"runs/{run}/config.json\")\n",
    "    configs.append(config)\n",
    "\n",
    "df_config = pd.DataFrame.from_records(configs)\n",
    "df_config[\"test_images\"] = df_config[\"test_images\"].str.replace(\"/workspace\", \".\")\n",
    "df_config[\"test_labels\"] = df_config[\"test_labels\"].str.replace(\"/workspace\", \".\")\n",
    "\n",
    "\n",
    "# load metrics\n",
    "df_train_list = []\n",
    "df_val_list = []\n",
    "df_test_list = []\n",
    "for run in RUNS:\n",
    "\n",
    "    # load jsons\n",
    "    data_train, data_val, data_test = get_metrics( filepath = f\"runs/{run}/metrics.json\" )\n",
    "\n",
    "    df_train = pd.DataFrame.from_records(data_train)\n",
    "    df_val = pd.DataFrame.from_records(data_val)\n",
    "    df_test = pd.DataFrame.from_records(data_test)\n",
    "\n",
    "\n",
    "    df_train[\"run\"] = run\n",
    "    df_val[\"run\"] = run\n",
    "    df_test[\"run\"] = run\n",
    "\n",
    "    # postprocessing\n",
    "    if len(df_val):\n",
    "        df_val = postprocess_df_val(df_val)\n",
    "\n",
    "    # postprocessing\n",
    "    if len(df_test):\n",
    "        df_test = postprocess_df_val(df_test)\n",
    "\n",
    "    df_train = postprocess(df_train)\n",
    "    df_val = postprocess(df_val)\n",
    "    df_test = postprocess(df_test)\n",
    "\n",
    "    df_train_list.append(df_train)\n",
    "    df_val_list.append(df_val)\n",
    "    df_test_list.append(df_test)\n",
    "\n",
    "df_train = pd.concat(df_train_list)\n",
    "df_val = pd.concat(df_val_list)\n",
    "df_test = pd.concat(df_test_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from PIL import Image\n",
    "from utils.metrics import iou_pytorch, batch_center_of_mass, max_diameter_and_angle, center_shapes\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from utils.metrics import min_angle_distance, max_diameter_and_angle, contour_length\n",
    "\n",
    "image_channels = 1\n",
    "batch_size = 8\n",
    "\n",
    "if image_channels == 3:\n",
    "    transforms = torchvision.transforms.Compose([\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "            ])\n",
    "elif image_channels == 1:\n",
    "    transforms = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Grayscale(num_output_channels=1),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.5), (0.5))\n",
    "        ])\n",
    "    \n",
    "\n",
    "        \n",
    "class ImageImageDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    A PyTorch Dataset class to be used in a PyTorch DataLoader to create batches of Images as tensor and Images raw.\n",
    "    The feature vectors have been one-hot encoded for categorical values and column-wise normalized.\n",
    "    \n",
    "    Attributes:\n",
    "        transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        image_files (list): List of image file paths.\n",
    "        captions (list): raw image.\n",
    "    \"\"\"\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.transform = transform\n",
    "        self.image_files1 = df[\"path_original\"].tolist()\n",
    "        self.image_files2 = df[\"path_generated\"].tolist()\n",
    "\n",
    "       \n",
    "    def __len__(self):\n",
    "        return len(self.image_files1)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image1 = Image.open(self.image_files1[idx])\n",
    "        image2 = Image.open(self.image_files2[idx])\n",
    "\n",
    "        if self.transform:\n",
    "            image1 = self.transform(image1)\n",
    "        if self.transform:\n",
    "            image2 = self.transform(image2)\n",
    "            \n",
    "        return image1, image2, self.image_files1[idx]\n",
    "    \n",
    "\n",
    "df = df_val.copy()\n",
    "df = df.loc[df[\"epoch\"]==925]\n",
    "df = df.loc[df[\"run\"]==\"2D_GeoShape_32_linear_cnn_image_1704819570\"]\n",
    "\n",
    "\n",
    "dataset = ImageImageDataset(df=df, transform=transforms)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "images1, images2, label = next(iter(dataloader))\n",
    "\n",
    "images1 = (images1 + 1) / 2\n",
    "images2 = (images2 + 1) / 2\n",
    "\n",
    "images1 = images1 > 0.5\n",
    "images2 = images2 > 0.5\n",
    "\n",
    "images1 = center_shapes(images1, threshold=0.5)\n",
    "images2 = center_shapes(images2, threshold=0.5)\n",
    "\n",
    "\n",
    "ious = iou_pytorch(images1, images2)\n",
    "\n",
    "fig, ax =  plt.subplots(2, math.ceil(len(images1)/2), figsize=(14,6))\n",
    "\n",
    "for i, (img1, img2, iou) in enumerate(zip(images1, images2, ious)):\n",
    "\n",
    "    \n",
    "    max_diameter1, max_angle1, pos1 = max_diameter_and_angle(img1)\n",
    "    max_diameter2, max_angle2, pos2 = max_diameter_and_angle(img2)\n",
    "    c1 = contour_length(img1)\n",
    "    c2 = contour_length(img2)\n",
    "\n",
    "    print(pos1)\n",
    "    absolute_angle_diff = min_angle_distance(max_angle1, max_angle2)\n",
    "    absolute_diameter_diff = abs(max_diameter1 - max_diameter2)\n",
    "    absolute_contour_diff = abs(c1 - c2)\n",
    " \n",
    "\n",
    "    print(absolute_angle_diff, absolute_diameter_diff, absolute_contour_diff)\n",
    "   \n",
    "    print(label[i].split('/')[-1])\n",
    "\n",
    "    image = np.zeros((img1.shape[1], img1.shape[2], 3))\n",
    "    image[:,:,0] = img1[0,:,:]\n",
    "    image[:,:,1] = img2[0,:,:]\n",
    "    ax[i%2, i//2].imshow(image)\n",
    "    ax[i%2, i//2].set_title(f\"IoU: {iou:.3f}\")\n",
    "#    ax[0].imshow(img1[0,:,:], cmap=\"gray\")\n",
    "#    ax[1].imshow(img2[0,:,:], cmap=\"gray\")\n",
    "   \n",
    "plt.suptitle(\"Visual overlap of generated shapes (red) and the corresponding ground truth (green).\\nThe intersection ot both shapes is yellow.\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L2 Center Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "idx = 520\n",
    "\n",
    "\n",
    "img1 = cv2.imread(df_val[\"path_generated\"].iat[idx])\n",
    "img2 = cv2.imread(df_val[\"path_original\"].iat[idx])\n",
    "\n",
    "sample_name = df_val[\"path_generated\"].iat[idx].split(\"/\")[-1]\n",
    "\n",
    "max_diameter1, max_angle1, pos1 = max_diameter_and_angle(img1)\n",
    "c1 = contour_length(img1)\n",
    "\n",
    "max_diameter2, max_angle2, pos2 = max_diameter_and_angle(img2)\n",
    "c2 = contour_length(img2)\n",
    "\n",
    "absolute_angle_diff = min_angle_distance(max_angle1, max_angle2)\n",
    "absolute_diameter_diff = abs(max_diameter1 - max_diameter2)\n",
    "absolute_contour_diff = abs(c1 - c2)\n",
    "\n",
    "print(c1, c2)\n",
    "absolute_angle_diff, absolute_diameter_diff, absolute_contour_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape Orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax =  plt.subplots(1, 2, figsize=(10,5))\n",
    "ax[0].imshow((img1[:,:,::-1]))\n",
    "for p1 in pos1:\n",
    "    ax[0].plot(p1[0], p1[1], \"-o\", label=\"Diameter\")\n",
    "ax[0].set_title(\"Generated shape\")\n",
    "\n",
    "ax[1].imshow((img2[:,:,::-1]))\n",
    "for p2 in pos2:\n",
    "    ax[1].plot(p2[0], p2[1], \"-o\")\n",
    "ax[1].set_title(\"Ground truth\")\n",
    "\n",
    "plt.text(x=0.5, y=1.1, s=\"Visual example of the shape diameter\", fontsize=18, ha=\"center\", transform=fig.transFigure)\n",
    "plt.text(x=0.5, y=0.98, s= f\"{sample_name}\\nγ_diff = {absolute_angle_diff:.2f}, D_diff = {absolute_diameter_diff:.2f}\", fontsize=12, ha=\"center\", transform=fig.transFigure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape contour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpack the points\n",
    "line1 = [[1,1], [4,4]]\n",
    "(x1, y1), (x2, y2) = line1\n",
    "\n",
    "\n",
    "# Calculate the direction of the lines\n",
    "dx1 = x2 - x1\n",
    "dy1 = y2 - y1\n",
    "\n",
    "\n",
    "# Calculate the angle between the lines\n",
    "angle1 = np.arctan([dy1, dx1])\n",
    "angle1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
