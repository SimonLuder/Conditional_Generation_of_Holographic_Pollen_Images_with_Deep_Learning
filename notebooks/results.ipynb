{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results Notebook\n",
    "\n",
    "This notebook visualizes the results from the trained models. It contains the figures which are used in the report, which means that interpretations of the individual graphics are mostly done in the report itself and are not present in the notebook. First, the logged metrics during training are shown. Next, the validation results are presented. Further down, the metrics on the test sets are visualized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import os\n",
    "import git\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def get_git_root(path):\n",
    "        git_repo = git.Repo(path, search_parent_directories=True)\n",
    "        git_root = git_repo.git.rev_parse(\"--show-toplevel\")\n",
    "        return git_root\n",
    "\n",
    "os.chdir(get_git_root(\".\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration of runs\n",
    "\n",
    "ENTITY=\"simonluder\"\n",
    "PROJECT=\"MSE_P7\"\n",
    "ARTIFACT = \"validation_results\"\n",
    "\n",
    "RUNS = [\n",
    "    \"2D_GeoShape_32_linear_tabular_1704819570\",\n",
    "    \"2D_GeoShape_32_linear_cnn_image_1704819570\",\n",
    "    \"2D_GeoShape_32_linear_clip_text_1704819570\",\n",
    "    \"2D_GeoShape_32_linear_clip_image_1704819570\",\n",
    "    \"2D_GeoShape_64_linear_tabular_1705056127\",\n",
    "    \"2D_GeoShape_64_linear_cnn_image_1705051540\",\n",
    "    \"2D_GeoShape_64_linear_clip_text_1705056262\",\n",
    "    \"2D_GeoShape_64_linear_clip_image_1705056262\", \n",
    "    \"2D_GeoShape_sub100_32_linear_tabular_1705411529\", \n",
    "    \"2D_GeoShape_sub100_32_linear_cnn_image_1705405821\", \n",
    "    \"2D_GeoShape_sub100_32_linear_clip_text_1705410786\",\n",
    "    \"2D_GeoShape_sub100_32_linear_clip_image_1705569629\"\n",
    "    \n",
    "    ]\n",
    "\n",
    "LOG_DIR = \"runs/\"\n",
    "\n",
    "download = True\n",
    "\n",
    "color_palette = {\"clip_text\": \"#7852A9\", \"clip_image\":\"#80de81\", \"tabular\": \"#4285c6\", \"cnn_image\":\"#8FD4CB\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "\n",
    "def get_config(filepath):\n",
    "\n",
    "    with open(filepath, 'r') as f:\n",
    "        return json.load(f)\n",
    "       \n",
    "\n",
    "def get_metrics(filepath):\n",
    "\n",
    "    with open(filepath, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    data_train = []\n",
    "    data_val = []\n",
    "    data_test = []\n",
    "\n",
    "    for entry in data:\n",
    "\n",
    "        entry_train = entry.get(\"train\")\n",
    "        entry_val = entry.get(\"val\")\n",
    "        entry_test = entry.get(\"test\")\n",
    "\n",
    "        if entry_train:\n",
    "            data_train.append(entry_train)\n",
    "\n",
    "        if entry_val:\n",
    "            data_val.append(entry_val)\n",
    "\n",
    "        if entry_test:\n",
    "            data_test.append(entry_test)\n",
    "\n",
    "    return data_train, data_val, data_test\n",
    "\n",
    "def postprocess_df_val(df_val):\n",
    "    df = df_val.explode('samples')\n",
    "    df = df.reset_index(drop=True)\n",
    "    df_samples = pd.json_normalize(df[\"samples\"])\n",
    "    df = pd.concat([df.drop(columns=['samples']), df_samples], axis=1)\n",
    "\n",
    "    df[\"path_original\"] = df[\"path_original\"].str.replace(\"/workspace\", \".\")\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def postprocess(df):\n",
    "    \n",
    "    pattern = r'(clip_text|clip_image|tabular|cnn_image)'\n",
    "    df['encoder'] = df['run'].str.extract(pattern, expand=False)\n",
    "\n",
    "    pattern = r'(_32_|_64_)'\n",
    "    df['image_size'] = df['run'].str.extract(pattern, expand=False).str.replace(\"_\", \"\").astype(int)\n",
    "\n",
    "    pattern = r'(sub100)'\n",
    "    df['subset'] = df['run'].str.extract(pattern, expand=False).str.replace(\"sub\", \"\")\n",
    "    df.loc[df['subset'].isna(), \"subset\"] = \"1000\"\n",
    "    df['subset'] = df['subset'].astype(int)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training datasets\n",
    "\n",
    "ds_path = \"./data\"\n",
    "\n",
    "# load dataset\n",
    "datasets = list()\n",
    "for dataset in os.listdir(ds_path):\n",
    "    dataset_path = os.path.join(ds_path, dataset, \"labels.csv\")\n",
    "    datasets.append(pd.read_csv(dataset_path))\n",
    "df_datasets = pd.concat(datasets)\n",
    "\n",
    "\n",
    "# load config\n",
    "configs = list()\n",
    "for run in RUNS:\n",
    "    config = get_config(filepath = f\"runs/{run}/config.json\")\n",
    "    configs.append(config)\n",
    "\n",
    "df_config = pd.DataFrame.from_records(configs)\n",
    "df_config[\"test_images\"] = df_config[\"test_images\"].str.replace(\"/workspace\", \".\")\n",
    "df_config[\"test_labels\"] = df_config[\"test_labels\"].str.replace(\"/workspace\", \".\")\n",
    "\n",
    "\n",
    "# load metrics\n",
    "df_train_list = []\n",
    "df_val_list = []\n",
    "df_test_list = []\n",
    "for run in RUNS:\n",
    "\n",
    "    # load jsons\n",
    "    data_train, data_val, data_test = get_metrics( filepath = f\"runs/{run}/metrics.json\" )\n",
    "\n",
    "    df_train = pd.DataFrame.from_records(data_train)\n",
    "    df_val = pd.DataFrame.from_records(data_val)\n",
    "    df_test = pd.DataFrame.from_records(data_test)\n",
    "\n",
    "\n",
    "    df_train[\"run\"] = run\n",
    "    df_val[\"run\"] = run\n",
    "    df_test[\"run\"] = run\n",
    "\n",
    "    # postprocessing\n",
    "    if len(df_val):\n",
    "        df_val = postprocess_df_val(df_val)\n",
    "\n",
    "    # postprocessing\n",
    "    if len(df_test):\n",
    "        df_test = postprocess_df_val(df_test)\n",
    "\n",
    "    df_train = postprocess(df_train)\n",
    "    df_val = postprocess(df_val)\n",
    "    df_test = postprocess(df_test)\n",
    "\n",
    "    df_train_list.append(df_train)\n",
    "    df_val_list.append(df_val)\n",
    "    df_test_list.append(df_test)\n",
    "\n",
    "df_train = pd.concat(df_train_list)\n",
    "df_val = pd.concat(df_val_list)\n",
    "df_test = pd.concat(df_test_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_32 = df_train.loc[(df_train[\"image_size\"]==32) & (df_train[\"subset\"]==1000)]\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "sns.lineplot(data=df_train_32, x=\"epoch\", y=\"epoch_loss\", hue=\"encoder\", palette=color_palette)\n",
    "plt.title(\"MSE loss for the models trained on train_32\")\n",
    "plt.ylabel(\"MSE loss per epoch\")\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_64 = df_train.loc[(df_train[\"image_size\"]==64) & (df_train[\"subset\"]==1000)]\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "sns.lineplot(data=df_train_64, x=\"epoch\", y=\"epoch_loss\", hue=\"encoder\", palette=color_palette)\n",
    "plt.title(\"MSE loss for the models train_64\")\n",
    "plt.ylabel(\"MSE loss per epoch\")\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_32_sub100 = df_train.loc[(df_train[\"image_size\"]==32) & (df_train[\"subset\"]==100)]\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "sns.lineplot(data=df_train_32_sub100, x=\"epoch\", y=\"epoch_loss\", hue=\"encoder\", palette=color_palette, alpha=0.6)\n",
    "plt.title(\"MSE loss for the models trained on train_32_sub100\")\n",
    "plt.ylabel(\"MSE loss per epoch\")\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following tables shows the best epoch during training per model, measured by the intersection over union on the validation dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add shape information from the training datasets from train data to the validation samples\n",
    "df_shapes_info = df_datasets[[\"im_res\", \"im_shape\",\"randomize\",\"shape_name\",\"radius\",\"x\",\"y\",\"rotation\",\"aspect_ratio\",\"fill_color\",\"bg_color\",\"file\"]]\n",
    "df_shapes_info_val = pd.merge(df_val, df_shapes_info, left_on='path_original', right_on='file')\n",
    "\n",
    "# get best epoch per run\n",
    "best_validation_epoch = df_shapes_info_val.iloc[df_shapes_info_val.groupby(\"run\")[\"mean_iou\"].idxmax()][[\"run\", \"epoch\", \"mean_iou\"]]\n",
    "best_validation_epoch\n",
    "# print(best_validation_epoch.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following table shows all metrics on the validation dataset for the best epoch per model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch_per_run = [(run, epoch) for run, epoch in zip(best_validation_epoch[\"run\"].to_list(), best_validation_epoch[\"epoch\"].to_list())]\n",
    "\n",
    "df_best_valdation_results = df_shapes_info_val[df_shapes_info_val.apply(lambda row: (row['run'], row['epoch']) in best_epoch_per_run, axis=1)]\n",
    "df_best_valdation_results = df_best_valdation_results.groupby([\"run\", \"epoch\"])[[\"IoU\", \"IoU_centered\", \"l2_distance\", \"abs_angle_diff\", \"abs_diameter_diff\", \"abs_contour_diff\"]].mean()\n",
    "df_best_valdation_results\n",
    "# print(df_best_valdation_results.to_latex(float_format=\"%.3f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Development of metrics during training\n",
    "\n",
    "To better examine the individual encoder variants and understand the training of the models, the metrics are calculated every 25 epochs on the validation dataset. The following subsection shows a visualization per selected metric of all models in relation to the epoch in training. The metrics compare the generated geometric shapes with the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_val = df_shapes_info_val.groupby([\"epoch\", \"run\"])[[\"IoU\", \"IoU_centered\", \"l2_distance\", \"abs_angle_diff\", \"abs_diameter_diff\", \"abs_contour_diff\"]].mean().reset_index()\n",
    "\n",
    "mean_val = postprocess(mean_val)\n",
    "\n",
    "mean_val_32 = mean_val.loc[(mean_val[\"image_size\"]==32) & (mean_val[\"subset\"]==1000)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Intersection over Union (IoU)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 3))\n",
    "sns.lineplot(data=mean_val_32, x=\"epoch\", y=\"IoU\", hue=\"encoder\", palette=color_palette)\n",
    "plt.title(\"Mean validation IoU during training\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure Centered Intersection over Union (IoU)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 3))\n",
    "sns.lineplot(data=mean_val_32, x=\"epoch\", y=\"IoU_centered\", hue=\"encoder\", palette=color_palette)\n",
    "plt.title(\"Mean centered validation IoU during training\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Centroid Distance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 3))\n",
    "sns.lineplot(data=mean_val_32, x=\"epoch\", y=\"l2_distance\", hue=\"encoder\", palette=color_palette)\n",
    "plt.title(\"Mean center distance during training\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mean absolute angular deviation of maximal diameter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 3))\n",
    "sns.lineplot(data=mean_val_32, x=\"epoch\", y=\"abs_angle_diff\", hue=\"encoder\", palette=color_palette)\n",
    "plt.title(\"Mean absolute angular deviation during training\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mean absolute difference in length of the maximum diameter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 3))\n",
    "sns.lineplot(data=mean_val_32, x=\"epoch\", y=\"abs_diameter_diff\", hue=\"encoder\", palette=color_palette)\n",
    "plt.title(\"Mean absolute diameter difference during training\")\n",
    "# plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mean absolute contour difference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 3))\n",
    "sns.lineplot(data=mean_val_32, x=\"epoch\", y=\"abs_contour_diff\", hue=\"encoder\", palette=color_palette)\n",
    "# plt.yscale(\"log\")\n",
    "plt.title(\"Mean contour difference during training\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "The following table shows the metrics obtained on the test data set. The model weights were selected for each model variant based on the best IoU on the validation dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_results = pd.merge(df_test, df_shapes_info, left_on='path_original', right_on='file')\n",
    "test_results = df_test_results.groupby([\"run\", \"epoch\"])[[\"IoU\", \"IoU_centered\", \"l2_distance\", \"abs_angle_diff\", \"abs_diameter_diff\", \"abs_contour_diff\"]].mean()\n",
    "test_results\n",
    "# print(test_results.to_latex(float_format=\"%.3f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test_results\n",
    "\n",
    "# def create_metricx_boxplot(df, metric, title):\n",
    "#     sns.boxplot(data=df, x=\"run\", y=metric)\n",
    "#     plt.title(title)\n",
    "                \n",
    "\n",
    "\n",
    "# create_metricx_boxplot(df_test_results, \"l2_distance\", \"IoU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "metrics = [\"IoU\", \"IoU_centered\", \"l2_distance\", \"abs_angle_diff\", \"abs_diameter_diff\", \"abs_contour_diff\"]\n",
    "runs = df_test_results[\"run\"].drop_duplicates()\n",
    "\n",
    "runs = [\"2D_GeoShape_32_linear_tabular_1704819570\",\n",
    "    \"2D_GeoShape_32_linear_cnn_image_1704819570\",\n",
    "    \"2D_GeoShape_32_linear_clip_text_1704819570\",\n",
    "    \"2D_GeoShape_32_linear_clip_image_1704819570\",]\n",
    "\n",
    "runs = RUNS\n",
    "\n",
    "df_cosine_similarities = list()\n",
    "\n",
    "df = df_test_results\n",
    "# df = df[[\"run\", \"path_original\"] + metrics]\n",
    "for i, run1 in enumerate(runs):\n",
    "    for j, run2 in enumerate(runs):\n",
    "\n",
    "        if i == j:\n",
    "            continue\n",
    "\n",
    "        print(run1, run2)\n",
    "\n",
    "        df1 = df.loc[df[\"run\"]==run1]\n",
    "        df2 = df.loc[df[\"run\"]==run2]\n",
    "\n",
    "        for i, row1 in df1.iterrows():\n",
    "  \n",
    "            sample = row1[\"path_original\"].split(\"/\")[-1]\n",
    "\n",
    "            v1 = df1.loc[df1[\"path_original\"].str.contains(sample)][metrics].reset_index(drop=True)\n",
    "            v2 = df2.loc[df2[\"path_original\"].str.contains(sample)][metrics].reset_index(drop=True)\n",
    "\n",
    "            # print(np.sum((v1.isna().values)))\n",
    "\n",
    "            \n",
    "            if np.sum((v1.isna().values)) + np.sum((v2.isna().values)) == 0:\n",
    "                similarity = cosine_similarity(v1, v2)[0][0]\n",
    "\n",
    "                df_cosine_similarities.append({\"run1\":run1, \"run2\":run2, \"sample\":sample, \"score\":similarity})\n",
    "            \n",
    "df_cosine_similarities = pd.DataFrame(df_cosine_similarities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity_mean = df_cosine_similarities.groupby([\"run1\", \"run2\"])[\"score\"].mean().reset_index()\n",
    "cosine_similarity_std = df_cosine_similarities.groupby([\"run1\", \"run2\"])[\"score\"].std().reset_index()\n",
    "\n",
    "cosine_mean_matrix = pd.DataFrame()\n",
    "cosine_similarity_mean\n",
    "\n",
    "for i, row in cosine_similarity_mean.iterrows():\n",
    "    cosine_mean_matrix.loc[row[\"run1\"], row[\"run2\"]] = row[\"score\"]\n",
    "\n",
    "sns.heatmap(cosine_mean_matrix)\n",
    "\n",
    "cosine_mean_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IoU on different shape types\n",
    "\n",
    "Intersection over Union as boxplot per shape. The IoU is combined for all model variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_results\n",
    "# rest_results_per_shape = df_test_results.groupby([\"run\", \"shape_name\"])[[\"IoU\", \"IoU_centered\"]].mean().reset_index()\n",
    "rest_results_per_shape = df_test_results\n",
    "rest_results_per_shape = postprocess(rest_results_per_shape)\n",
    "\n",
    "\n",
    "pattern = r'(sub100_32_linear|32_linear|64_linear)'\n",
    "rest_results_per_shape['variant'] = rest_results_per_shape['run'].str.extract(pattern, expand=False)\n",
    "rest_results_per_shape['testset, trainset'] = rest_results_per_shape['variant'].replace({\"sub100_32_linear\":\"test32, train32_sub100\",\n",
    "                                                                                             \"32_linear\":\"test32, train32\",\n",
    "                                                                                             \"64_linear\":\"test64, train64\"})\n",
    "df_test_results['encoder, testset, trainset'] = df_test_results[\"encoder\"] + \", \" + df_test_results['testset, trainset']\n",
    "\n",
    "# Create a boxplot\n",
    "def boxplot_iou_per_shape(df, y):\n",
    "    order = ['circle', 'triangle', 'square', 'pentagon', 'hexagon', 'heptagon', 'octagon', 'nonagon', 'star']\n",
    "    plt.figure(figsize=(12,4))\n",
    "    ax = sns.boxplot(x='shape_name', y=y, data=df, order=order)\n",
    "    plt.title(f'Mean IoU per shape on the testing set')\n",
    "    plt.xlabel(\"shape type\")\n",
    "    plt.ylabel(y)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "boxplot_iou_per_shape(rest_results_per_shape, y=\"IoU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a boxplot\n",
    "def boxplot_iou_per_shape(df, y):\n",
    "    order = ['circle', 'triangle', 'square', 'pentagon', 'hexagon', 'heptagon', 'octagon', 'nonagon', 'star']\n",
    "    plt.figure(figsize=(12,4))\n",
    "    hue_order = [\"clip_image, test32, train32\",\n",
    "                 \"clip_image, test32, train32_sub100\",\n",
    "                 \"clip_image, test64, train64\",\n",
    "                 \"clip_text, test32, train32\",\n",
    "                 \"clip_text, test32, train32_sub100\",\n",
    "                 \"clip_text, test64, train64\",\n",
    "                 \"cnn_image, test32, train32\",\n",
    "                 \"cnn_image, test32, train32_sub100\",\n",
    "                 \"cnn_image, test64, train64\",\n",
    "                 \"tabular, test32, train32\",\n",
    "                 \"tabular, test32, train32_sub100\",\n",
    "                 \"tabular, test64, train64\",\n",
    "                 ]\n",
    "    ax = sns.boxplot(x='shape_name', y=y, data=df, order=order, hue='encoder, testset, trainset', hue_order=hue_order)\n",
    "    sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 1))\n",
    "    plt.title(f'Mean IoU per shape on the testing set')\n",
    "    plt.xlabel(\"shape type\")\n",
    "    plt.ylabel(y)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "boxplot_iou_per_shape(rest_results_per_shape, y=\"IoU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Centroid adjusted IoU on different shape types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def show_bin_prop_diameter(df, step=10):\n",
    "\n",
    "    plt.figure(figsize=(12,5))\n",
    "\n",
    "    vmin = math.floor(df['prop_diameter'].min() / step) \n",
    "    vmax = math.ceil(df['prop_diameter'].max() / step) \n",
    "    bins = np.arange(vmin, vmax + 1, 1) * step\n",
    "\n",
    "    df['prop_diameter_binned'] = pd.cut(df['prop_diameter'], bins).sort_values()\n",
    "  \n",
    "    df = df.groupby(['encoder, testset, trainset', \"prop_diameter_binned\"])[\"IoU\"].mean().reset_index()\n",
    "    df['prop_diameter_binned'] = df['prop_diameter_binned'].astype(str)\n",
    "\n",
    "    ax = sns.lineplot(data=df, x=\"prop_diameter_binned\", y=\"IoU\", hue='encoder, testset, trainset')\n",
    "    sns.scatterplot(data=df, x=\"prop_diameter_binned\", y=\"IoU\", hue='encoder, testset, trainset', legend=False)\n",
    "    sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 1))\n",
    "    plt.xticks(rotation = -90)\n",
    "\n",
    "    plt.title(\"Intersection over Union in relation to shape diameter\")\n",
    "    plt.ylabel(\"IoU\")\n",
    "    plt.xlabel(\"propotional diameter\")\n",
    "    plt.show()\n",
    "\n",
    "df_test_results[\"prop_diameter\"] = (df_test_results[\"radius\"] * 2) / 256\n",
    "df_test_results = postprocess(df_test_results)\n",
    "df_test_results[\"variant\"] = df_test_results['encoder'].astype(str) + \", size:\" + df_test_results['image_size'].astype(str) + \", samples:\" + df_test_results['subset'].astype(str)\n",
    "\n",
    "\n",
    "pattern = r'(sub100_32_linear|32_linear|64_linear)'\n",
    "df_test_results['variant'] = df_test_results['run'].str.extract(pattern, expand=False)\n",
    "df_test_results['datasets: test, train'] = df_test_results['variant'].replace({\"sub100_32_linear\":\"test32, train32_sub100\",\n",
    "                                                                                             \"32_linear\":\"test32, train32\",\n",
    "                                                                                             \"64_linear\":\"test64, train64\"})\n",
    "df_test_results['encoder, testset, trainset'] = df_test_results[\"encoder\"] + \", \" + df_test_results['datasets: test, train']\n",
    "\n",
    "show_bin_prop_diameter(df_test_results, step=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_bin_prop_diameter(df, step=10):\n",
    "\n",
    "    plt.figure(figsize=(12,5))\n",
    "\n",
    "    vmin = math.floor(df['prop_diameter'].min() / step) \n",
    "    vmax = math.ceil(df['prop_diameter'].max() / step) \n",
    "    bins = np.arange(vmin, vmax + 1, 1) * step\n",
    "\n",
    "    df['prop_diameter_binned'] = pd.cut(df['prop_diameter'], bins).sort_values()\n",
    "  \n",
    "    df = df.groupby(['encoder, testset, trainset', \"prop_diameter_binned\"])[\"IoU_centered\"].mean().reset_index()\n",
    "    df['prop_diameter_binned'] = df['prop_diameter_binned'].astype(str)\n",
    "\n",
    "    ax = sns.lineplot(data=df, x=\"prop_diameter_binned\", y=\"IoU_centered\", hue='encoder, testset, trainset')\n",
    "    sns.scatterplot(data=df, x=\"prop_diameter_binned\", y=\"IoU_centered\", hue='encoder, testset, trainset', legend=False)\n",
    "    sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 1))\n",
    "    plt.xticks(rotation = -90)\n",
    "\n",
    "    plt.title(\"Center adjusted Intersection over Union in relation to shape diameter\")\n",
    "    plt.ylabel(\"IoU_centered\")\n",
    "    plt.xlabel(\"propotional diameter\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "show_bin_prop_diameter(df_test_results, step=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def test(df, step=10):\n",
    "\n",
    "    plt.figure(figsize=(12,5))\n",
    "    \n",
    "\n",
    "\n",
    "    vmin = math.floor(df['prop_diameter'].min() / step) \n",
    "    vmax = math.ceil(df['prop_diameter'].max() / step) \n",
    "    bins = np.arange(vmin, vmax + 1, 1) * step\n",
    "\n",
    "    df['prop_diameter_binned'] = pd.cut(df['prop_diameter'], bins).sort_values()\n",
    "        \n",
    "    df = df.groupby([\"run\", \"prop_diameter_binned\", \"image_size\"])[\"IoU\"].mean().reset_index()\n",
    "    df['prop_diameter_binned'] = df['prop_diameter_binned'].astype(str)\n",
    "\n",
    "    sns.boxplot(x='prop_diameter_binned', y=\"IoU\", data=df, hue=\"image_size\")\n",
    "    plt.xticks(rotation = -90)\n",
    "\n",
    "    plt.title(\"Intersection over Union in relation to shape diameter\")\n",
    "    plt.xlabel(\"proportional diameter\")\n",
    "\n",
    "\n",
    "iou_per_size = df_test_results.loc[~df_test_results[\"run\"].str.contains(\"sub100\")]\n",
    "\n",
    "\n",
    "test(iou_per_size, step=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qualitative Evaluation on the Test Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "from matplotlib.patches import Rectangle\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "test_samples = df_test_results[\"path_original\"].apply(lambda x: x.split(\"/\")[-1]).drop_duplicates().to_list()[0:9]\n",
    "\n",
    "fig, ax = plt.subplots(len(test_samples), len(RUNS) + 1, figsize=(13, 1 * len(test_samples)))\n",
    "outergs = gridspec.GridSpec(1, 1)\n",
    "\n",
    "\n",
    "\n",
    "for i, sample in enumerate(test_samples):\n",
    "    for j, run in enumerate(RUNS):\n",
    "        sub_df = df_test_results.loc[df_test_results[\"path_original\"].str.contains(sample) &  df_test_results[\"run\"].str.contains(run)]\n",
    "        image_file = sub_df[\"path_generated\"].values[0]\n",
    "        variant = sub_df[\"encoder, testset, trainset\"].values[0]      \n",
    "\n",
    "        image_file = sub_df[\"path_generated\"].values[0]\n",
    "        im = cv2.imread(image_file)\n",
    "        ax[i, j+1].imshow(im)\n",
    "\n",
    "        if i == 0:\n",
    "            ax[i, j+1].set_title(variant.replace(\" test\", \"\\ntest\"), rotation=-90, size=10)\n",
    "\n",
    "        if j == 0:\n",
    "            image_file_gt = os.path.join(\"data/test256/images/\", sample)\n",
    "            im = cv2.imread(image_file_gt)\n",
    "            ax[i, j].imshow(im)\n",
    "\n",
    "            ax[i, j].set_xticks([])\n",
    "            ax[i, j].set_yticks([])\n",
    "\n",
    "            txt = ax[i, j].text(-30, 120, textwrap.fill(sample, 20), horizontalalignment='right', verticalalignment='center', wrap=True)\n",
    "\n",
    "            if i == 0:\n",
    "                ax[i, j].set_title(\"ground truth\\n@ 256 x 256\", rotation=-90, size=10)\n",
    "\n",
    "                \n",
    "\n",
    "        ax[i, j+1].set_xticks([])\n",
    "        ax[i, j+1].set_yticks([])\n",
    "\n",
    "rect = Rectangle((0.18, 1.03), -0.059, -0.93, facecolor='yellow', edgecolor='none',\n",
    "                 transform=fig.transFigure, zorder=-1)\n",
    "fig.patches.append(rect)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "from matplotlib.patches import Rectangle\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "test_samples = df_test_results[\"path_original\"].apply(lambda x: x.split(\"/\")[-1]).drop_duplicates().to_list()\n",
    "\n",
    "fig, ax = plt.subplots(len(test_samples), len(RUNS) + 1, figsize=(13, 1 * len(test_samples)))\n",
    "outergs = gridspec.GridSpec(1, 1)\n",
    "\n",
    "\n",
    "\n",
    "for i, sample in enumerate(test_samples):\n",
    "    for j, run in enumerate(RUNS):\n",
    "        sub_df = df_test_results.loc[df_test_results[\"path_original\"].str.contains(sample) &  df_test_results[\"run\"].str.contains(run)]\n",
    "        image_file = sub_df[\"path_generated\"].values[0]\n",
    "        variant = sub_df[\"encoder, testset, trainset\"].values[0]      \n",
    "\n",
    "        image_file = sub_df[\"path_generated\"].values[0]\n",
    "        im = cv2.imread(image_file)\n",
    "        ax[i, j+1].imshow(im)\n",
    "\n",
    "        if i == 0:\n",
    "            ax[i, j+1].set_title(variant.replace(\" test\", \"\\ntest\"), rotation=-90, size=10)\n",
    "\n",
    "        if j == 0:\n",
    "            image_file_gt = os.path.join(\"data/test256/images/\", sample)\n",
    "            im = cv2.imread(image_file_gt)\n",
    "            ax[i, j].imshow(im)\n",
    "\n",
    "            ax[i, j].set_xticks([])\n",
    "            ax[i, j].set_yticks([])\n",
    "\n",
    "            txt = ax[i, j].text(-30, 120, textwrap.fill(sample, 20), horizontalalignment='right', verticalalignment='center', wrap=True)\n",
    "\n",
    "            if i == 0:\n",
    "                ax[i, j].set_title(\"ground truth\\n@ 256 x 256\", rotation=-90, size=10)\n",
    "\n",
    "                \n",
    "\n",
    "        ax[i, j+1].set_xticks([])\n",
    "        ax[i, j+1].set_yticks([])\n",
    "\n",
    "rect = Rectangle((0.18, 1.03), -0.059, -0.93, facecolor='yellow', edgecolor='none',\n",
    "                 transform=fig.transFigure, zorder=-1)\n",
    "fig.patches.append(rect)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_list(lst, n):\n",
    "    return [lst[i::n] for i in range(0, n, 1)]\n",
    "\n",
    "\n",
    "test_samples = df_test_results[\"path_original\"].apply(lambda x: x.split(\"/\")[-1]).drop_duplicates().to_list()\n",
    "test_samples = split_list(test_samples, 9)\n",
    "\n",
    "\n",
    "\n",
    "for test_samples_figure in test_samples:\n",
    "    fig, ax = plt.subplots(len(test_samples[0]), len(RUNS) + 1, figsize=(13, 1 * len(test_samples[0])))\n",
    "    outergs = gridspec.GridSpec(1, 1)\n",
    "    for i, sample in enumerate(test_samples_figure):\n",
    "        for j, run in enumerate(RUNS):\n",
    "            sub_df = df_test_results.loc[df_test_results[\"path_original\"].str.contains(sample) &  df_test_results[\"run\"].str.contains(run)]\n",
    "            image_file = sub_df[\"path_generated\"].values[0]\n",
    "            variant = sub_df[\"encoder, testset, trainset\"].values[0]      \n",
    "\n",
    "            image_file = sub_df[\"path_generated\"].values[0]\n",
    "            im = cv2.imread(image_file)\n",
    "            ax[i, j+1].imshow(im)\n",
    "\n",
    "            if i == 0:\n",
    "                ax[i, j+1].set_title(variant.replace(\" test\", \"\\ntest\"), rotation=-90, size=10)\n",
    "\n",
    "            if j == 0:\n",
    "                image_file_gt = os.path.join(\"data/test256/images/\", sample)\n",
    "                im = cv2.imread(image_file_gt)\n",
    "                ax[i, j].imshow(im)\n",
    "\n",
    "                ax[i, j].set_xticks([])\n",
    "                ax[i, j].set_yticks([])\n",
    "\n",
    "                txt = ax[i, j].text(-30, 120, textwrap.fill(sample, 20), horizontalalignment='right', verticalalignment='center', wrap=True)\n",
    "\n",
    "                if i == 0:\n",
    "                    ax[i, j].set_title(\"ground truth\\n@ 256 x 256\", rotation=-90, size=10)\n",
    "\n",
    "                    \n",
    "\n",
    "            ax[i, j+1].set_xticks([])\n",
    "            ax[i, j+1].set_yticks([])\n",
    "\n",
    "    rect = Rectangle((0.18, 1.03), -0.059, -0.93, facecolor='yellow', edgecolor='none',\n",
    "                    transform=fig.transFigure, zorder=-1)\n",
    "    fig.patches.append(rect)\n",
    "\n",
    "\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "three_D",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
