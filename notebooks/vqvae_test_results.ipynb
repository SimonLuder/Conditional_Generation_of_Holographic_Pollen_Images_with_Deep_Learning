{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VQ-VAE Results\n",
    "\n",
    "This notebook contains the results from the training, validation and testing of the VQ-VAE models. The interpretation of the tables and graphs can be found in the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "workdir = \"Generative Diffusion Models for 3D Geometric Objects\"\n",
    "if workdir in os.getcwd() and os.path.basename(os.getcwd()) != workdir:\n",
    "    os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Validation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of the VQVAE models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    \"vqvae_autoencoder_3_512\",\n",
    "    \"vqvae_autoencoder_3_2048\",\n",
    "    \"vqvae_autoencoder_3_8192\",\n",
    "    \"vqvae_autoencoder_8_512\",\n",
    "    \"vqvae_autoencoder_8_2048\",\n",
    "    \"vqvae_autoencoder_8_8192\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First the logged metrics collected during the training and validation of the models is downloaded from WandB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize the wandb API\n",
    "api = wandb.Api()\n",
    "\n",
    "# Get the runs for a specific project\n",
    "entity = \"simonluder\"\n",
    "project_name = \"MSE_P8\"\n",
    "runs = api.runs(f'{entity}/{project_name}')\n",
    "run_names = [f\"{model_name}_vqvae\" for model_name in model_names]\n",
    "\n",
    "# Loop through the runs and download the one with the specific name\n",
    "for run in runs:\n",
    "    \n",
    "    if run.name in run_names:\n",
    "\n",
    "        if not os.path.exists(f'holographic_pollen/{run.name.replace(\"_vqvae\", \"\")}/metrics.csv'):\n",
    "\n",
    "            print(f\"Downloading: {run.name}\")\n",
    "            run_id = run.id\n",
    "\n",
    "            # download metrics from the history artifact\n",
    "            artifact = api.artifact(name=f'{entity}/{project_name}/run-{run_id}-history:latest', type='wandb-history')\n",
    "            filename = artifact.file(\"temp/wandb/\")\n",
    "\n",
    "            # create csv\n",
    "            df = pd.read_parquet(filename)\n",
    "            df.to_csv(f'holographic_pollen/{run.name.replace(\"_vqvae\", \"\")}/metrics.csv', index=False)\n",
    "\n",
    "            shutil.rmtree(\"temp/wandb/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After downloading, the metrics are loaded as pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []\n",
    "\n",
    "for model_name in model_names:\n",
    "    df = pd.read_csv(f\"holographic_pollen/{model_name}/metrics.csv\")\n",
    "    df.loc[:, \"model_name\"] = model_name.replace(\"_autoencoder\", \"\")\n",
    "    metrics.append(df)\n",
    "\n",
    "metrics = pd.concat(metrics).reset_index(drop=True)\n",
    "\n",
    "metrics.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next the validation loss of the different models is visualized. The Loss is calculated as MSE over all samples in the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "sns.lineplot(data=metrics, x=\"step\", y=\"val_epoch_reconstructon_loss\", hue=\"model_name\")\n",
    "plt.title(\"Mean Squared Error on the validation set\")\n",
    "plt.yscale(\"log\")\n",
    "plt.ylabel(\"Mean Squared Error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Testing\n",
    "\n",
    "### 2.1 Quantitative Evaluation of the Reconstructed Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the ground truth testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truh_labels = pd.read_csv(\"labels_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "files = [\"vqvae_autoencoder_3_512\", \n",
    "         \"vqvae_autoencoder_3_2048\",\n",
    "         \"vqvae_autoencoder_3_8192\",\n",
    "         \"vqvae_autoencoder_8_512\",\n",
    "         \"vqvae_autoencoder_8_2048\",\n",
    "         \"vqvae_autoencoder_8_8192\"\n",
    "         ]\n",
    "\n",
    "df_errors = list()\n",
    "for file in files:\n",
    "    with open(f\"holographic_pollen/{file}/test/lpips_scores.pkl\", \"rb\") as f:\n",
    "        df = pd.DataFrame.from_dict(pickle.load(f))\n",
    "        df[\"model\"] = file.replace(\"_autoencoder\", \"\")\n",
    "        df_errors.append(df)\n",
    "df_errors = pd.concat(df_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Sqaured Error per image as boxplot per model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "sns.boxplot(x='model', y='mse_scores', data=df_errors, flierprops={'marker': 'x', 'markersize': 4})\n",
    "plt.title('Mean squared error on generated images for the testset')\n",
    "plt.ylabel('Mean squared error')\n",
    "plt.xlabel('model')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "print(df_errors.groupby(\"model\")[\"mse_scores\"].quantile([0.25, 0.5, 0.75]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LPIPS per image as boxplot per model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "sns.boxplot(x='model', y='lpips_scores', data=df_errors, flierprops={'marker': 'x', 'markersize': 4})\n",
    "plt.title('LPIPS error on generated images for the testset')\n",
    "plt.ylabel('LPIPS error')\n",
    "plt.xlabel('model')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "print(df_errors.groupby(\"model\")[\"lpips_scores\"].quantile([0.25, 0.5, 0.75]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Qualitative Evaluation of the Reconstructed Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = []\n",
    "for model_name in model_names:\n",
    "    df = pd.read_json(f\"holographic_pollen/{model_name}/test/test_logs.json\")\n",
    "    df.loc[:, \"model_name\"] = model_name\n",
    "    df[\"dataset_id\"] = df[\"filenames\"].apply(lambda x: os.path.split(x)[0])\n",
    "    df[\"rec_path\"] = df[\"filenames\"].apply(lambda x: os.path.split(x)[1])\n",
    "    test_results.append(df)\n",
    "\n",
    "test_results = pd.concat(test_results).reset_index(drop=True)\n",
    "test_results[\"model\"] = test_results[\"model_name\"].apply(lambda x: x.replace(\"_autoencoder\", \"\"))\n",
    "\n",
    "test_results.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, individual reconstructed samples from the sub-submitted vqvae variants are visualized and compared with the ground truth image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = test_results.loc[test_results[\"filenames\"] == test_results[\"filenames\"].sample(1).values[0]].reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(1, len(samples)+1, figsize=(14, 5))\n",
    "\n",
    "gt_path = os.path.join(\"Z:\\marvel\\marvel-fhnw\\data\\Poleno\", samples.at[0, \"dataset_id\"], samples.at[0, \"rec_path\"])\n",
    "\n",
    "\n",
    "ax[0].imshow(cv2.imread(gt_path))\n",
    "ax[0].set_title(\"ground_truth\", size=10)\n",
    "ax[0].tick_params(left = False, right = False , labelleft = False , labelbottom = False, bottom = False)\n",
    "\n",
    "for i, row in samples.iterrows():\n",
    "   rel_path = f'holographic_pollen/{row[\"model_name\"]}/test/images/{row[\"rec_path\"]}'\n",
    "   img_generated = cv2.imread(rel_path)\n",
    "   ax[i+1].imshow(img_generated)\n",
    "   ax[i+1].set_title(row[\"model\"], size=10)\n",
    "   ax[i+1].tick_params(left = False, right = False , labelleft = False , labelbottom = False, bottom = False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select samples from the ground truth test set\n",
    "sample_filenames = ground_truh_labels.groupby(\"label\").head(1).sort_values(by=\"label\")[\"rec_path\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of the first image per label from the test dataset. The first column represents the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add ground truth labels to the dataframe\n",
    "test_results = pd.merge(test_results, ground_truh_labels[['dataset_id', 'rec_path', 'label']], on=['dataset_id', 'rec_path'], how='left')\n",
    "\n",
    "# Number of samples to display\n",
    "num_samples = len(set(test_results[\"label\"]))\n",
    "\n",
    "# Filter the test results for the selected samples\n",
    "samples = test_results[test_results[\"rec_path\"].isin(sample_filenames)].reset_index()\n",
    "\n",
    "# Calculate the number of subplots required\n",
    "samples_per_subplot = 8  # Number of samples per subplot\n",
    "num_subplots = (num_samples + samples_per_subplot - 1) // samples_per_subplot  # Calculate the number of subplots needed\n",
    "num_cols = len(samples[samples[\"rec_path\"] == sample_filenames[0]]) + 1\n",
    "num_rows = samples_per_subplot\n",
    "\n",
    "# Iterate through each subplot\n",
    "for subplot_idx in range(num_subplots):\n",
    "    # Create a figure for each subplot\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(2 * num_cols, 2.3 * num_rows))\n",
    "    \n",
    "    # Iterate through the samples for the current subplot\n",
    "    for row_idx in range(num_rows):\n",
    "        sample_idx = subplot_idx * samples_per_subplot + row_idx\n",
    "        if sample_idx >= num_samples:\n",
    "            break\n",
    "        \n",
    "        sample_filename = sample_filenames[sample_idx]\n",
    "        # Get the subset of samples for the current filename\n",
    "        sample_subset = samples[samples[\"rec_path\"] == sample_filename].reset_index()\n",
    "        \n",
    "        # Display the ground truth image\n",
    "        gt_path = os.path.join(\"Z:/marvel/marvel-fhnw/data/Poleno\", sample_subset.at[0, \"dataset_id\"], sample_subset.at[0, \"rec_path\"])\n",
    "        ground_truth_image = cv2.imread(gt_path)\n",
    "        axes[row_idx, 0].imshow(ground_truth_image)\n",
    "        axes[row_idx, 0].set_title(\"Ground Truth\", size=12)\n",
    "        axes[row_idx, 0].tick_params(left=False, right=False, labelleft=False, labelbottom=False, bottom=False)\n",
    "        \n",
    "        # Display the generated images for each sample\n",
    "        for col_idx, row in sample_subset.iterrows():\n",
    "            rel_path = f'holographic_pollen/{row[\"model_name\"]}/test/images/{row[\"rec_path\"]}'\n",
    "            generated_image = cv2.imread(rel_path)\n",
    "            axes[row_idx, col_idx + 1].imshow(generated_image)\n",
    "            axes[row_idx, col_idx + 1].set_title(row[\"model\"], size=12)\n",
    "            axes[row_idx, col_idx + 1].tick_params(left=False, right=False, labelleft=False, labelbottom=False, bottom=False)\n",
    "        \n",
    "        # Set the label as subtitle for each row\n",
    "        fig.text(-0.1, (num_rows - row_idx - 0.5) / num_rows, sample_subset.at[0, \"label\"], ha='center', va='center', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    # Adjust layout and show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "three_D",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
